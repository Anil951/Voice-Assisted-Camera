{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera ON\n",
      "Listening for commands...\n",
      "Listening...\n",
      "Command: hello hello 123 mike testing\n",
      "Listening...\n",
      "no command detected\n",
      "Listening...\n",
      "Command: change filter\n",
      "Listening...\n",
      "Command: change filter\n",
      "Listening...\n",
      "Command: change filter\n",
      "Listening...\n",
      "Command: default view\n",
      "Listening...\n",
      "Command: zoom\n",
      "Listening...\n",
      "Command: zoom in\n",
      "Listening...\n",
      "Command: zoom in\n",
      "Listening...\n",
      "Command: zoom out\n",
      "Listening...\n",
      "Command: capture\n",
      "Image captured and saved as 'captured_images/image_0.jpg'\n",
      "Listening...\n",
      "no command detected\n",
      "Listening...\n",
      "Command: start recording\n",
      "Recording Started...\n",
      "Listening...\n",
      "Audio recording started...\n",
      "Command: hello 1234\n",
      "Listening...\n",
      "no command detected\n",
      "Listening...\n",
      "Command: pause recording\n",
      "Recording Paused...\n",
      "Listening...\n",
      "Command: resume recording\n",
      "Recording Resumed...\n",
      "Listening...\n",
      "Command: zoom out\n",
      "Listening...\n",
      "Command: change filter\n",
      "Listening...\n",
      "Command: change filter\n",
      "Listening...\n",
      "Command: now I am changing filters using keys\n",
      "Listening...\n",
      "no command detected\n",
      "Listening...\n",
      "Command: capture\n",
      "Image captured and saved as 'captured_images/image_1.jpg'\n",
      "Listening...\n",
      "Command: stop recording\n",
      "Audio recording stopped...\n",
      "Recording Stopped.\n",
      "Listening...\n",
      "Command: stop Camera\n",
      "stopping camera\n"
     ]
    }
   ],
   "source": [
    "#MAIN CODE FINALLLL --WITH ALL FEATURESSSS -- WITH INSTUCTIONS\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "import subprocess\n",
    "\n",
    "# Function to convert text to speech\n",
    "def SpeakText(command):\n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Function to capture photo\n",
    "photo_count = 0\n",
    "zoomed_frame = None  # Global variable to hold the zoomed frame\n",
    "current_filter_index = 0  # Global variable to track the current filter index\n",
    "recording = False\n",
    "paused = False\n",
    "paused_lock = threading.Lock()  # Lock for synchronizing pausing/resuming\n",
    "\n",
    "# Audio recording parameters\n",
    "audio_format = pyaudio.paInt16\n",
    "channels = 1\n",
    "sample_rate = 44100\n",
    "chunk_size = 1024\n",
    "\n",
    "# Global variables for audio recording\n",
    "audio_stream = None\n",
    "audio_frames = []\n",
    "\n",
    "# Flag to indicate whether audio recording is completed\n",
    "audio_completed = threading.Event()\n",
    "\n",
    "def capture_photo():\n",
    "    global photo_count, zoomed_frame, current_filter_index\n",
    "    if zoomed_frame is not None:\n",
    "        # Apply the current filter to the zoomed frame\n",
    "        filtered_frame = apply_filters(zoomed_frame)\n",
    "        # Filename for saving the image\n",
    "        filename = f\"captured_images/image_{photo_count}.jpg\"\n",
    "        # Write the image with the current filter applied\n",
    "        cv2.imwrite(filename, filtered_frame)\n",
    "        # Speak the recognized text\n",
    "        SpeakText(\"captured photo\")\n",
    "        print(f\"Image captured and saved as '{filename}'\")\n",
    "        photo_count += 1\n",
    "    else:\n",
    "        SpeakText(\"Failed to capture photo\")\n",
    "        print(\"Failed to capture photo!\")\n",
    "\n",
    "# Function for zooming in and out\n",
    "scale = 1\n",
    "def zoom_frame(img):\n",
    "    global scale\n",
    "    height, width = img.shape[:2]\n",
    "    center_x, center_y = width / 2, height / 2\n",
    "    radius_x, radius_y = int(scale * width / 2), int(scale * height / 2)\n",
    "    min_x, max_x = int(center_x - radius_x), int(center_x + radius_x)\n",
    "    min_y, max_y = int(center_y - radius_y), int(center_y + radius_y)\n",
    "    cropped = img[min_y:max_y, min_x:max_x]\n",
    "    return cv2.resize(cropped, (width, height))\n",
    "\n",
    "def zoom_out():\n",
    "    global scale\n",
    "    if scale < 1:\n",
    "        scale += 0.1\n",
    "\n",
    "def zoom_in():\n",
    "    global scale\n",
    "    if scale > 0.2:\n",
    "        scale -= 0.1\n",
    "\n",
    "# Function to apply different color space conversions\n",
    "def apply_filters(frame):\n",
    "    global current_filter_index\n",
    "\n",
    "    # Function to invert the frame colors\n",
    "    def apply_invert(frame):\n",
    "        return cv2.bitwise_not(frame)\n",
    "\n",
    "    # Function to verify alpha channel\n",
    "    def verify_alpha_channel(frame):\n",
    "        try:\n",
    "            frame.shape[3] # 4th position\n",
    "        except IndexError:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA)\n",
    "        return frame\n",
    "\n",
    "    # Function to apply color overlay\n",
    "    def apply_color_overlay(frame, intensity=0.2, blue=0, green=0, red=0):\n",
    "        frame = verify_alpha_channel(frame)\n",
    "        frame_h, frame_w, frame_c = frame.shape\n",
    "        color_bgra = (blue, green, red, 1)\n",
    "        overlay = np.full((frame_h, frame_w, 4), color_bgra, dtype='uint8')\n",
    "        cv2.addWeighted(overlay, intensity, frame, 1.0, 0, frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "        return frame\n",
    "\n",
    "    # Function to apply sepia effect\n",
    "    def apply_sepia(frame, intensity=0.5):\n",
    "        blue = 20\n",
    "        green = 66 \n",
    "        red = 112\n",
    "        frame = apply_color_overlay(frame, intensity=intensity, blue=blue, green=green, red=red)\n",
    "        return frame\n",
    "\n",
    "    # Apply filters based on current index\n",
    "    if current_filter_index == 0:\n",
    "        return frame\n",
    "    elif current_filter_index == 1:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif current_filter_index == 2:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    elif current_filter_index == 3:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    elif current_filter_index == 4:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "    elif current_filter_index == 5:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)\n",
    "    elif current_filter_index == 6:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2HLS)\n",
    "    elif current_filter_index == 7:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2XYZ)\n",
    "    elif current_filter_index == 8:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2LUV)\n",
    "    elif current_filter_index == 9:\n",
    "        return cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    elif current_filter_index == 10:\n",
    "        return apply_invert(frame)\n",
    "    elif current_filter_index == 11:\n",
    "        return apply_color_overlay(frame.copy(), intensity=.5, red=230, blue=10)\n",
    "    elif current_filter_index == 12:\n",
    "        return apply_sepia(frame.copy())\n",
    "\n",
    "# Function to listen for voice commands\n",
    "def listen_for_commands():\n",
    "    global running\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for commands...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        while running:\n",
    "            print(\"Listening...\")\n",
    "            try:\n",
    "                audio = recognizer.listen(source)  # Set timeout to 1 second\n",
    "                command = recognizer.recognize_google(audio)\n",
    "                print(\"Command:\", command)\n",
    "                handle_command(command)\n",
    "            except:\n",
    "                print(\"no command detected\")\n",
    "\n",
    "def handle_command(command):\n",
    "    global recording, paused\n",
    "    command=command.lower()\n",
    "    if \"capture\" in command:\n",
    "        capture_photo()\n",
    "    elif \"stop camera\" in command:\n",
    "        print(\"stopping camera\")\n",
    "        SpeakText(\"stopping camera\")\n",
    "        stop_camera()\n",
    "    elif \"zoom in\" in command:\n",
    "        SpeakText(\"zoomed in\")\n",
    "        zoom_in()\n",
    "    elif \"zoom out\" in command:\n",
    "        SpeakText(\"zoomed out\")\n",
    "        zoom_out()\n",
    "    elif \"change filter\" in command:\n",
    "        next_filter()\n",
    "    elif \"default view\" in command:\n",
    "        SpeakText(\"default view\")\n",
    "        set_default_view()\n",
    "    elif \"start recording\" in command:\n",
    "        if not recording:\n",
    "            record_start()\n",
    "    elif \"stop recording\" in command:\n",
    "        if recording:\n",
    "            record_stop()\n",
    "    elif \"pause recording\" in command:\n",
    "        if recording and not paused:\n",
    "            record_pause()\n",
    "    elif \"resume recording\" in command:\n",
    "        if recording and paused:\n",
    "            record_resume()\n",
    "\n",
    "def next_filter():\n",
    "    global current_filter_index\n",
    "    current_filter_index = (current_filter_index + 1) % 13  # Change 13 to the total number of filters added above\n",
    "\n",
    "def set_default_view():\n",
    "    global current_filter_index\n",
    "    current_filter_index = 0\n",
    "\n",
    "def record_audio():\n",
    "    global recording, audio_frames, audio_completed, paused\n",
    "    audio = pyaudio.PyAudio()\n",
    "    audio_frames = []\n",
    "    audio_stream = audio.open(format=audio_format, channels=channels,\n",
    "                              rate=sample_rate, input=True,\n",
    "                              frames_per_buffer=chunk_size)\n",
    "    print(\"Audio recording started...\")\n",
    "    while recording:\n",
    "        with paused_lock:\n",
    "            if paused:\n",
    "                continue\n",
    "        audio_data = audio_stream.read(chunk_size)\n",
    "        audio_frames.append(audio_data)\n",
    "    print(\"Audio recording stopped...\")\n",
    "    audio_stream.stop_stream()\n",
    "    audio_stream.close()\n",
    "    audio.terminate()\n",
    "    audio_completed.set()\n",
    "\n",
    "def record_video():\n",
    "    global recording, paused, audio_frames\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('captured_images/output.mp4', fourcc, 13.0, (640, 480))  # Adjust frame rate \n",
    "\n",
    "    while recording:\n",
    "        with paused_lock:\n",
    "            if paused:\n",
    "                continue\n",
    "        ret, frame = camera.read()\n",
    "        if ret:\n",
    "            zoomed_frame = zoom_frame(frame)\n",
    "            filtered_frame = apply_filters(zoomed_frame)\n",
    "            cv2.imshow(\"Camera\", filtered_frame)\n",
    "            out.write(filtered_frame)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('p'):\n",
    "                print(\"Recording Paused...\")\n",
    "                SpeakText(\"recording paused\")\n",
    "                out.release()\n",
    "                with paused_lock:\n",
    "                    paused = True\n",
    "                while paused:\n",
    "                    continue\n",
    "                with paused_lock:\n",
    "                    paused = False\n",
    "                print(\"Recording Resumed...\")\n",
    "                SpeakText(\"recording resumed\")\n",
    "            elif key == ord('q'):\n",
    "                print(\"stopping camera\")\n",
    "                SpeakText(\"stopping camera\")\n",
    "                stop_camera()\n",
    "    # Release the VideoWriter object\n",
    "    out.release()\n",
    "\n",
    "def record_start():\n",
    "    global recording\n",
    "    recording = True\n",
    "    SpeakText(\"recording started\")\n",
    "    print(\"Recording Started...\")\n",
    "    # Start record_audio() in a separate thread\n",
    "    audio_thread = threading.Thread(target=record_audio)\n",
    "    audio_thread.start()\n",
    "    # Start record_video() in a separate thread\n",
    "    video_thread = threading.Thread(target=record_video)\n",
    "    video_thread.start()\n",
    "\n",
    "def record_stop():\n",
    "    global recording, audio_completed\n",
    "    recording = False\n",
    "    SpeakText(\"recording stopped\")\n",
    "    print(\"Recording Stopped.\")\n",
    "    # Wait for audio recording to complete\n",
    "    audio_completed.wait()\n",
    "    # Save recorded audio to file\n",
    "    save_audio()\n",
    "\n",
    "def save_audio():\n",
    "    global audio_frames\n",
    "    wave_file = wave.open(\"captured_images/audio.wav\", 'wb')\n",
    "    wave_file.setnchannels(channels)\n",
    "    wave_file.setsampwidth(pyaudio.PyAudio().get_sample_size(audio_format))\n",
    "    wave_file.setframerate(sample_rate)\n",
    "    wave_file.writeframes(b''.join(audio_frames))\n",
    "    wave_file.close()\n",
    "\n",
    "def record_pause():\n",
    "    global paused\n",
    "    with paused_lock:\n",
    "        paused = True\n",
    "    SpeakText(\"recording paused\")\n",
    "    print(\"Recording Paused...\")\n",
    "\n",
    "def record_resume():\n",
    "    global paused\n",
    "    with paused_lock:\n",
    "        paused = False\n",
    "    SpeakText(\"recording resumed\")\n",
    "    print(\"Recording Resumed...\")\n",
    "\n",
    "def stop_camera():\n",
    "    global running\n",
    "    running = False\n",
    "\n",
    "# Create a directory to save the captured images\n",
    "if not os.path.exists(\"captured_images\"):\n",
    "    os.makedirs(\"captured_images\")\n",
    "\n",
    "# Initialize camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "print(\"camera ON\")\n",
    "\n",
    "# Flag to indicate whether the threads should continue running\n",
    "running = True\n",
    "\n",
    "# Start voice command thread\n",
    "listen_thread = threading.Thread(target=listen_for_commands)\n",
    "listen_thread.start()\n",
    "\n",
    "# Start camera loop\n",
    "while running:\n",
    "    ret, frame = camera.read()\n",
    "    if ret:\n",
    "        # Create a blank image for displaying text\n",
    "        text_frame = 255 * np.ones((frame.shape[0], frame.shape[1] // 2, 3), dtype=np.uint8)\n",
    "\n",
    "        # Add text to the blank image\n",
    "        commands = [\n",
    "            \"               INSTRUCTIONS         \",\n",
    "            \"                             \",\n",
    "            \"Say 'capture' or press 'c' \",\n",
    "            \"                to capture photo\",\n",
    "            \"Say 'stop camera' or press 'q'\",\n",
    "            \"                to stop the camera\",\n",
    "            \"Say 'zoom in' or press 'z'\",\n",
    "            \"                to zoom in the screen\",\n",
    "            \"Say 'zoom out'or press 'x' \",\n",
    "            \"                to zoom out the screen\",\n",
    "            \"Say 'change filter' or press 'n'\",\n",
    "            \"                to change the filter\",\n",
    "            \"Say 'default view' or press 'd' \",\n",
    "            \"                 to set to default view\",\n",
    "            \"Say 'start recording' or press 'r' \",\n",
    "            \"                 to start recording the video\",\n",
    "            \"Say 'stop recording' or press 'r' \",\n",
    "            \"                 to stop the recording video\",\n",
    "            \"Say 'pause recording' or press 'p' \",\n",
    "            \"                 to pause the recording\",\n",
    "            \"Say 'resume recording' or press 'p' \",\n",
    "            \"                  to resume the recording\"\n",
    "        ]\n",
    "        \n",
    "        for i, command in enumerate(commands):\n",
    "            org = (20, 50 + (i+1)*15)  # Position of the text, adjusted for smaller font\n",
    "            cv2.putText(text_frame, command, org, cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1, cv2.LINE_AA)  # Adjusted font size\n",
    "\n",
    "        \n",
    "        # Display instructions\n",
    "        cv2.imshow('Instructions', text_frame)\n",
    "\n",
    "        # cv2.setWindowProperty(\"Instructions\", cv2.WND_PROP_TOPMOST, 1)  # Set window always on top\n",
    "\n",
    "        zoomed_frame = zoom_frame(frame)\n",
    "        filtered_frame = apply_filters(zoomed_frame)\n",
    "        cv2.imshow(\"Camera\", filtered_frame)\n",
    "\n",
    "        # cv2.setWindowProperty(\"Camera\", cv2.WND_PROP_TOPMOST, 1)  # Set window always on top\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            print(\"stopping camera\")\n",
    "            SpeakText(\"stopping camera\")\n",
    "            stop_camera()\n",
    "        elif key == ord('z'):\n",
    "            zoom_in()\n",
    "        elif key == ord('x'):\n",
    "            zoom_out()\n",
    "        elif key == ord('c'):\n",
    "            capture_photo()\n",
    "        elif key == ord('n'):\n",
    "            next_filter()\n",
    "        elif key == ord('d'):\n",
    "            set_default_view()\n",
    "        elif key == ord('r'):\n",
    "            if not recording:\n",
    "                record_start()\n",
    "            else:\n",
    "                record_stop()\n",
    "        elif key == ord('p'):\n",
    "            if recording:\n",
    "                if not paused:\n",
    "                    record_pause()\n",
    "                else:\n",
    "                    record_resume()\n",
    "\n",
    "# Release camera\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# to merge audio(wav) with video(mp4)\n",
    "def merge_video_audio(video_path,audio_path,output_path):\n",
    "    command = ['ffmpeg', '-i', video_path, '-i', audio_path, '-c:v', 'copy', '-c:a', 'aac', output_path]\n",
    "    subprocess.run(command, capture_output=True, check=True)\n",
    "\n",
    "# Paths to video and audio files\n",
    "video_file = \"captured_images/output.mp4\"\n",
    "audio_file = \"captured_images/audio.wav\"\n",
    "output_file = \"captured_images/final.mp4\"\n",
    "\n",
    "# Merge video and audio files\n",
    "merge_video_audio(video_file,audio_file,output_file)\n",
    "\n",
    "os.remove(video_file)\n",
    "os.remove(audio_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
